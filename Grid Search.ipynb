{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faeaea91",
   "metadata": {},
   "source": [
    "Grid search to determine best hyperparameters\n",
    "\n",
    "Hyperparameters tuned: Number of filters, Filter size, # of Dense nodes\n",
    "\n",
    "Best model: 16 filter, Size 4, 16 Dense nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f009b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9104dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recieves data and applies z-score standardisation on all channels\n",
    "def standardise(stored_data):\n",
    "    scaler = StandardScaler()\n",
    "    standard_stored_data = scaler.fit_transform(stored_data)\n",
    "    return standard_stored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2450bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code was made by adapting original code by Wen et. al (2021)\n",
    "#Provided in their paper: \"A convolutional neural network to identify motor units\n",
    "#from high-density surface electromyography signals inreal time\"\n",
    "#Original code can be found here: https://github.com/ywen3/dcnn_mu_decomp/blob/main/hdEMG_DCNN.ipynb\n",
    "\n",
    "#Used for calculating RoA during model training\n",
    "\n",
    "def RoA_m(y_true, y_pred):\n",
    "    threshold = 3*tf.math.reduce_std(y_pred)\n",
    "    y_pred_binary = tf.where(y_pred>=threshold, 1., 0.)\n",
    "    y_comp = y_pred_binary + y_true\n",
    "    true_positives = tf.shape(tf.where(y_comp == 2))[0]\n",
    "    unmatched = tf.shape(tf.where(y_comp == 1))[0]\n",
    "    return true_positives/(true_positives + unmatched)\n",
    "\n",
    "\n",
    "class AccuracyCallback(Callback):\n",
    "    def __init__(self, metric_name = 'accuracy'):\n",
    "        super().__init__()\n",
    "        self.metric_name = metric_name\n",
    "        self.val_metric = []\n",
    "        self.metric = []\n",
    "        self.val_metric_mean = 0\n",
    "        self.metric_mean = 0\n",
    "        self.best_metric = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('Accuracycallback')\n",
    "        # extract values from logs\n",
    "        self.val_metric = []\n",
    "        self.metric = []\n",
    "        for log_name, log_value in logs.items():\n",
    "            if log_name.find(self.metric_name) != -1:\n",
    "                if log_name.find('val') != -1:\n",
    "                    self.val_metric.append(log_value)\n",
    "                else:\n",
    "                    self.metric.append(log_value)\n",
    "\n",
    "        self.val_metric_mean = np.mean(self.val_metric)\n",
    "        self.metric_mean = np.mean(self.metric)\n",
    "        logs['val_{}'.format(self.metric_name)] = np.mean(self.val_metric)   # replace it with your metrics\n",
    "        logs['{}'.format(self.metric_name)] = np.mean(self.metric)   # replace it with your metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e8357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the RoA given model predictions and true labels Y\n",
    "def singleModelRoA(predictions, Y):\n",
    "    y_pred = tf.squeeze(predictions)\n",
    "    threshold = 3*np.std(y_pred,axis = 1)\n",
    "    match = 0\n",
    "    unmatch = 0\n",
    "    for MU in range(len(Y)):\n",
    "        pred_spikes, _ = find_peaks(y_pred[MU], height = threshold[MU], distance = 2)\n",
    "        true_spikes = tf.squeeze(tf.where(np.array(Y)[MU] == 1))\n",
    "        a = set(true_spikes.numpy())\n",
    "        b = set(pred_spikes)\n",
    "        matches = len(a.intersection(b))\n",
    "        unmatched1 = a - b\n",
    "        unmatched2 = b - a\n",
    "        tolerance = len([x for x in unmatched1 if (x+1 in unmatched2 or x-1 in unmatched2)])\n",
    "        match = match + matches + tolerance\n",
    "        unmatch = unmatch + len(unmatched1) + len(unmatched2) - (2*tolerance)\n",
    "    return match/(match + unmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02163e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for standardising and windowing training signal\n",
    "def windowtrain(EMGtrain, spiketrain, window_size):\n",
    "    \n",
    "    EMGtrain = standardise(EMGtrain)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(30,EMGtrain.shape[0]-120):\n",
    "        \n",
    "        if any(spiketrain[i, 0:5] == 1):\n",
    "            x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "            y_train.append(spiketrain[i, 0:5])\n",
    "        else:\n",
    "            if random.uniform(0, 1) < .05:\n",
    "                x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "                y_train.append(spiketrain[i, 0:5])\n",
    "    y_train = np.array(y_train)\n",
    "    y_train2 = []\n",
    "    for i in range(5):\n",
    "        y_train2.append(y_train[:,i])\n",
    "    \n",
    "    return np.array(x_train), y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954ceb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for windowing test signal, predictions are recieved \n",
    "#from the model in batches to limit memory issues\n",
    "def windowtest(EMGtrain, spiketrain, window_size, model):\n",
    "    \n",
    "    EMGtrain = standardise(EMGtrain)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    predictions = []\n",
    "    count = 1\n",
    "    for i in range(30,EMGtrain.shape[0]-120):\n",
    "        x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "        y_train.append(spiketrain[i, 0:5])\n",
    "        if count%8162 == 0:\n",
    "            predictions.append(model(np.array(x_train)))\n",
    "            x_train = []\n",
    "        count = count + 1\n",
    "            \n",
    "    y_train = np.array(y_train)\n",
    "    y_train2 = []\n",
    "    for i in range(5):\n",
    "        y_train2.append(y_train[:,i])\n",
    "    \n",
    "    return tf.concat(predictions, axis = 1), y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d48ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs a CNN model that recieves a HD-sEMG signal window as input and outputs\n",
    "#a 0 or 1 label based on wether the respective MU it has been trained to detect\n",
    "#is present in the signal. The number of these models in parallel can be given by MUs\n",
    "def convolutional_model(input_shape, filter_num, filter_size, dense_num, MUs):\n",
    "    input_signal = tf.keras.Input(shape = input_shape)\n",
    "    out = []\n",
    "    for i in range(1, MUs+1):\n",
    "        X = tfl.Conv1D(filter_num, filter_size, activation = 'relu')(input_signal)\n",
    "        X = tfl.Dropout(0.2)(X)\n",
    "        X = tfl.Flatten()(X)\n",
    "        X = tfl.Dense(dense_num, activation='relu')(X)\n",
    "        X = tfl.Dropout(0.5)(X)\n",
    "        output = tfl.Dense(1, activation = 'sigmoid', name='output_{}'.format(i))(X)\n",
    "        out.append(output)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input_signal, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea64c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds and compiles CNN model based on given parameters\n",
    "def build_model(window_size, filter_num, filter_size, dense_num, MUs):\n",
    "    model= convolutional_model((window_size, 192), filter_num, filter_size, dense_num, MUs)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  metrics = ['accuracy',RoA_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520ce92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines multiple 20s generated signals into a larger training set.\n",
    "#Does not include the test set\n",
    "def getFoldTrainingSet(test_fold, window_size):  \n",
    "    #random.seed(60)\n",
    "    training_folds = np.delete([1,2,3,4,5],test_fold-1)\n",
    "    iter = False\n",
    "    for fold in training_folds:\n",
    "        EMGtrain = np.load('noise_data/30dB_fold{}_x.npy'.format(fold))\n",
    "        spikes = np.load('noise_data/30dB_fold{}_y.npy'.format(fold))\n",
    "        fold_windows , fold_spikes = windowtrain(EMGtrain, spikes, window_size)\n",
    "        if iter == False:\n",
    "            X = fold_windows\n",
    "            Y = fold_spikes\n",
    "        else:\n",
    "            X = np.concatenate((X, fold_windows), axis = 0)\n",
    "            for i in range(len(Y)):\n",
    "                Y[i] = np.concatenate((Y[i],fold_spikes[i]))\n",
    "        iter = True\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8002d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains model and saves model that achieves best RoA on the validaiton set and the final model\n",
    "def trainModel(model,X_train,Y_train, filter_num, filter_size, dense_num, MUs, test_fold):\n",
    "    mc_vR= ModelCheckpoint('tuning_m/best_{}fnum_{}fsize_{}dnum_fold{}.h5'.format(filter_num, filter_size, dense_num, test_fold), monitor='val_RoA_m', mode='max', verbose=0, save_best_only=True)\n",
    "    RoA_callback = AccuracyCallback('RoA_m')\n",
    "    history = model.fit(X_train,\n",
    "                        Y_train,\n",
    "                        shuffle = True,\n",
    "                        epochs = 100,\n",
    "                        validation_split=0.2,\n",
    "                        batch_size=256,\n",
    "                        verbose = 0,\n",
    "                        callbacks = [RoA_callback, mc_vR])\n",
    "    model.save('tuning_m/final_{}fnum_{}fsize_{}dnum_fold{}.h5'.format(filter_num, filter_size, dense_num, test_fold))\n",
    "    print('{}fnum_{}fsize_{}dnum_fold{} trained'.format(filter_num, filter_size, dense_num, test_fold))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5761387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applied grid search training\n",
    "window_size = 60\n",
    "MUs = 5\n",
    "random.seed(60)\n",
    "for filter_num in [4,8,16]:\n",
    "    for filter_size in [3,4,5]:\n",
    "        for dense_num in [8, 16, 32]:\n",
    "            dist = [1,2,3,4,5]\n",
    "            for test_fold in dist:\n",
    "                conv_model = build_model(window_size, filter_num, filter_size, dense_num, MUs)\n",
    "                X_train, Y_train = getFoldTrainingSet(test_fold, window_size)\n",
    "                trainModel(conv_model, X_train, Y_train, filter_num, filter_size, dense_num, MUs, test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2c7b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4fnum_3fsize_8dnum\n",
      "0.971210014282331\n",
      "4fnum_3fsize_16dnum\n",
      "0.9734248631266661\n",
      "4fnum_3fsize_32dnum\n",
      "0.9662514039879815\n",
      "4fnum_4fsize_8dnum\n",
      "0.9766938692311449\n",
      "4fnum_4fsize_16dnum\n",
      "0.9773561553833996\n",
      "4fnum_4fsize_32dnum\n",
      "0.976391374801295\n",
      "4fnum_5fsize_8dnum\n",
      "0.971670870898594\n",
      "4fnum_5fsize_16dnum\n",
      "0.9732618753889971\n",
      "4fnum_5fsize_32dnum\n",
      "0.9677323794527327\n",
      "8fnum_3fsize_8dnum\n",
      "0.9676458748369878\n",
      "8fnum_3fsize_16dnum\n",
      "0.9706411795027157\n",
      "8fnum_3fsize_32dnum\n",
      "0.9572538371270722\n",
      "8fnum_4fsize_8dnum\n",
      "0.9707605948220914\n",
      "8fnum_4fsize_16dnum\n",
      "0.9754843720383987\n",
      "8fnum_4fsize_32dnum\n",
      "0.9710371806013047\n",
      "8fnum_5fsize_8dnum\n",
      "0.975552171612933\n",
      "8fnum_5fsize_16dnum\n",
      "0.9758203665344787\n",
      "8fnum_5fsize_32dnum\n",
      "0.9706037976453823\n",
      "16fnum_3fsize_8dnum\n",
      "0.9668947003520371\n",
      "16fnum_3fsize_16dnum\n",
      "0.9608222636047101\n",
      "16fnum_3fsize_32dnum\n",
      "0.9676458782186771\n",
      "16fnum_4fsize_8dnum\n",
      "0.9698732964574116\n",
      "16fnum_4fsize_16dnum\n",
      "0.9801148164561735\n",
      "16fnum_4fsize_32dnum\n",
      "0.9646112286017452\n",
      "16fnum_5fsize_8dnum\n",
      "0.9739285291609642\n",
      "16fnum_5fsize_16dnum\n",
      "0.9754018963560183\n",
      "16fnum_5fsize_32dnum\n",
      "0.9712383593690472\n"
     ]
    }
   ],
   "source": [
    "for filter_num in [4,8,16]:\n",
    "    for filter_size in [3,4,5]:\n",
    "        for dense_num in [8, 16, 32]:\n",
    "            RoAs = np.zeros(5)\n",
    "            for fold in [1,2,3,4,5]:\n",
    "                EMGtest=np.load('noise_data/30dB_fold{}_x.npy'.format(fold))\n",
    "                spikes = np.load('noise_data/30dB_fold{}_y.npy'.format(fold))\n",
    "                conv_model2 = load_model('tuning_m/best_{}fnum_{}fsize_{}dnum_fold{}.h5'.format(filter_num, filter_size, dense_num, fold), custom_objects={\"RoA_m\": RoA_m})\n",
    "                predictions, Y = windowtest(EMGtest, spikes, window_size, conv_model2)\n",
    "                RoAs[fold-1] = singleModelRoA(predictions, np.array(Y))\n",
    "            print('{}fnum_{}fsize_{}dnum'.format(filter_num, filter_size, dense_num))\n",
    "            print(np.mean(RoAs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a1745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
