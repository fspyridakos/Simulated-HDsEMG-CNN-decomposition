{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e943f52d",
   "metadata": {},
   "source": [
    "Code for Measuring Model Computation Time\n",
    "\n",
    "Single and 5-model ensemble compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2c64aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from scipy.signal import find_peaks\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fa902d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recieves data and applies z-score standardisation on all channels\n",
    "def standardise(stored_data):\n",
    "    scaler = StandardScaler()\n",
    "    standard_stored_data = scaler.fit_transform(stored_data)\n",
    "    return standard_stored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93f42da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code was made by adapting original code by Wen et. al (2021)\n",
    "#Provided in their paper: \"A convolutional neural network to identify motor units\n",
    "#from high-density surface electromyography signals inreal time\"\n",
    "#Original code can be found here: https://github.com/ywen3/dcnn_mu_decomp/blob/main/hdEMG_DCNN.ipynb\n",
    "\n",
    "#Used for calculating RoA during model training\n",
    "\n",
    "def RoA_m(y_true, y_pred):\n",
    "    threshold = 3*tf.math.reduce_std(y_pred)\n",
    "    y_pred_binary = tf.where(y_pred>=threshold, 1., 0.)\n",
    "    y_comp = y_pred_binary + y_true\n",
    "    true_positives = tf.shape(tf.where(y_comp == 2))[0]\n",
    "    unmatched = tf.shape(tf.where(y_comp == 1))[0]\n",
    "    return true_positives/(true_positives + unmatched)\n",
    "\n",
    "\n",
    "class AccuracyCallback(Callback):\n",
    "    def __init__(self, metric_name = 'accuracy'):\n",
    "        super().__init__()\n",
    "        self.metric_name = metric_name\n",
    "        self.val_metric = []\n",
    "        self.metric = []\n",
    "        self.val_metric_mean = 0\n",
    "        self.metric_mean = 0\n",
    "        self.best_metric = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('Accuracycallback')\n",
    "        # extract values from logs\n",
    "        self.val_metric = []\n",
    "        self.metric = []\n",
    "        for log_name, log_value in logs.items():\n",
    "            if log_name.find(self.metric_name) != -1:\n",
    "                if log_name.find('val') != -1:\n",
    "                    self.val_metric.append(log_value)\n",
    "                else:\n",
    "                    self.metric.append(log_value)\n",
    "\n",
    "        self.val_metric_mean = np.mean(self.val_metric)\n",
    "        self.metric_mean = np.mean(self.metric)\n",
    "        logs['val_{}'.format(self.metric_name)] = np.mean(self.val_metric)   # replace it with your metrics\n",
    "        logs['{}'.format(self.metric_name)] = np.mean(self.metric)   # replace it with your metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f35c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window incloming signal and fit a scaler to transform data online\n",
    "def windowtime(EMGtrain, spiketrain, window_size):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(EMGtrain)\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(30,EMGtrain.shape[0]-120):\n",
    "        x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "        y_train.append(spiketrain[i, 0:5])\n",
    "    \n",
    "    return np.array(x_train), np.array(y_train), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1395759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provides the predictoins of the ensmble with naive weighting\n",
    "def naiveEnsemblePredict(output):\n",
    "    y_pred = tf.math.add_n(output)\n",
    "    y_pred = tf.squeeze(y_pred,2)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7136f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates the ensemble model by combining multiple models\n",
    "def ensemble_model_gen(input_shape, names):\n",
    "    input_signal = tf.keras.Input(shape = input_shape)\n",
    "    out = []\n",
    "    \n",
    "    for i in names:\n",
    "        output = load_model(i, custom_objects={\"RoA_m\": RoA_m})(input_signal)\n",
    "        out.append(output)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input_signal, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d030e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets 1 second from a 30 dB, 20 MU, no lowpassing, no shift signal and extracts windows and scaler\n",
    "var = 'noise'\n",
    "noise = '30dB'\n",
    "fold = 1\n",
    "EMGtest = np.load('{}_data/{}_fold{}_x.npy'.format(var, noise, fold))[0:2048]\n",
    "spikes = np.load('{}_data/{}_fold{}_y.npy'.format(var, noise, fold))[0:2048]\n",
    "X , Y, scaler = windowtime(EMGtest, spikes, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5fac9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get single model\n",
    "conv_model = load_model('{}_models/bestvR_big_fold{}.h5'.format(var, fold), custom_objects={\"RoA_m\": RoA_m})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0d9ee",
   "metadata": {},
   "source": [
    "Computation time and decompostion rate is measured for both models\n",
    "\n",
    "Time to standardise incoming windows and decompose window batch is included in the prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2411578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time: 19.86106236775716 ms\n",
      "Decomposition rate (needs to be >2048): 2114.6905045816493\n"
     ]
    }
   ],
   "source": [
    "comp_time = []\n",
    "spike = []\n",
    "stack = 42 #batch of windows to be decomposed at once\n",
    "prepare = conv_model(X[0:stack])\n",
    "for k  in range(0, X.shape[0]-11,stack):\n",
    "    EMG = X[k:(k+stack)]\n",
    "    start_time = time.time()\n",
    "    #Standardise incoming signal\n",
    "    for i in range(EMG.shape[0]):\n",
    "        EMG[i] = scaler.transform(EMG[i])\n",
    "    predictions = conv_model(EMG)\n",
    "    comp_time.append(time.time() - start_time)\n",
    "    spike.append(tf.squeeze(predictions))\n",
    "print('Computation time: '+ str((np.mean(comp_time))*1000) + ' ms')\n",
    "print('Decomposition rate (needs to be >2048): ' + str(1/(np.mean(comp_time)/stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca3bc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = ['20dB','15dB','10dB','5dB','0dB']\n",
    "names = []\n",
    "for n in noises:\n",
    "    names.append('{}_models/bestvR_{}_fold{}.h5'.format(var, n, fold))\n",
    "ensemble_model = ensemble_model_gen((60, 192), names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "132ca51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time: 90.75460433959961 ms\n",
      "Decomposition rate (needs to be >2048): 2115.5951413940907\n"
     ]
    }
   ],
   "source": [
    "comp_time = []\n",
    "spike = []\n",
    "stack = 192 #batch of windows to be decomposed at once\n",
    "prepare = ensemble_model(X[0:stack])\n",
    "for k in range(0, X.shape[0]-11,stack):\n",
    "    EMG = X[k:(k+stack)]\n",
    "    start_time = time.time()\n",
    "    #Standardise incoming signal\n",
    "    for i in range(EMG.shape[0]):\n",
    "        EMG[i] = scaler.transform(EMG[i])\n",
    "    predictions = naiveEnsemblePredict(ensemble_model(EMG))\n",
    "    comp_time.append(time.time() - start_time)\n",
    "    spike.append(tf.squeeze(predictions))\n",
    "print('Computation time: '+ str((np.mean(comp_time))*1000) + ' ms')\n",
    "print('Decomposition rate (needs to be >2048): ' + str(1/(np.mean(comp_time)/stack)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
