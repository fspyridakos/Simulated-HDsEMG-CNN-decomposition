{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571645e3",
   "metadata": {},
   "source": [
    "Code for training smaller models on stationary signals described by Experiment 2.\n",
    "\n",
    "CNN model trained on full non-stationary training set.\n",
    "\n",
    "5 times for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ec1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbef7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function two shuffle 2 arrays in the same way\n",
    "#Aquired from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13391ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recieves data and applies z-score standardisation on all channels\n",
    "def standardise(stored_data):\n",
    "    scaler = StandardScaler()\n",
    "    standard_stored_data = scaler.fit_transform(stored_data)\n",
    "    return standard_stored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310d0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code was made by adapting original code by Wen et. al (2021)\n",
    "#Provided in their paper: \"A convolutional neural network to identify motor units\n",
    "#from high-density surface electromyography signals inreal time\"\n",
    "#Original code can be found here: https://github.com/ywen3/dcnn_mu_decomp/blob/main/hdEMG_DCNN.ipynb\n",
    "\n",
    "#Used for calculating RoA during model training\n",
    "\n",
    "def RoA_m(y_true, y_pred):\n",
    "    threshold = 3*tf.math.reduce_std(y_pred)\n",
    "    y_pred_binary = tf.where(y_pred>=threshold, 1., 0.)\n",
    "    y_comp = y_pred_binary + y_true\n",
    "    true_positives = tf.shape(tf.where(y_comp == 2))[0]\n",
    "    unmatched = tf.shape(tf.where(y_comp == 1))[0]\n",
    "    return true_positives/(true_positives + unmatched)\n",
    "\n",
    "\n",
    "class AccuracyCallback(Callback):\n",
    "    def __init__(self, metric_name = 'accuracy'):\n",
    "        super().__init__()\n",
    "        self.metric_name = metric_name\n",
    "        self.val_metric = []\n",
    "        self.metric = []\n",
    "        self.val_metric_mean = 0\n",
    "        self.metric_mean = 0\n",
    "        self.best_metric = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('Accuracycallback')\n",
    "        # extract values from logs\n",
    "        self.val_metric = []\n",
    "        self.metric = []\n",
    "        for log_name, log_value in logs.items():\n",
    "            if log_name.find(self.metric_name) != -1:\n",
    "                if log_name.find('val') != -1:\n",
    "                    self.val_metric.append(log_value)\n",
    "                else:\n",
    "                    self.metric.append(log_value)\n",
    "\n",
    "        self.val_metric_mean = np.mean(self.val_metric)\n",
    "        self.metric_mean = np.mean(self.metric)\n",
    "        logs['val_{}'.format(self.metric_name)] = np.mean(self.val_metric)   # replace it with your metrics\n",
    "        logs['{}'.format(self.metric_name)] = np.mean(self.metric)   # replace it with your metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fcfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the RoA given model predictions and true labels Y\n",
    "def singleModelRoA(predictions, Y):\n",
    "    y_pred = tf.squeeze(predictions)\n",
    "    threshold = 3*np.std(y_pred,axis = 1)\n",
    "    match = 0\n",
    "    unmatch = 0\n",
    "    for MU in range(len(Y)):\n",
    "        pred_spikes, _ = find_peaks(y_pred[MU], height = threshold[MU], distance = 2)\n",
    "        true_spikes = tf.squeeze(tf.where(np.array(Y)[MU] == 1))\n",
    "        a = set(true_spikes.numpy())\n",
    "        b = set(pred_spikes)\n",
    "        matches = len(a.intersection(b))\n",
    "        unmatched1 = a - b\n",
    "        unmatched2 = b - a\n",
    "        tolerance = len([x for x in unmatched1 if (x+1 in unmatched2 or x-1 in unmatched2)])\n",
    "        match = match + matches + tolerance\n",
    "        unmatch = unmatch + len(unmatched1) + len(unmatched2) - (2*tolerance)\n",
    "    return match/(match + unmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ad8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for standardising and windowing training signal\n",
    "def windowtrain(EMGtrain, spiketrain, window_size):\n",
    "    \n",
    "    EMGtrain = standardise(EMGtrain)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(30,EMGtrain.shape[0]-120):\n",
    "        \n",
    "        if any(spiketrain[i, 0:5] == 1):\n",
    "            x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "            y_train.append(spiketrain[i, 0:5])\n",
    "        else:\n",
    "            if random.uniform(0, 1) < .05:\n",
    "                x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "                y_train.append(spiketrain[i, 0:5])\n",
    "    y_train = np.array(y_train)\n",
    "    y_train2 = []\n",
    "    for i in range(5):\n",
    "        y_train2.append(y_train[:,i])\n",
    "    \n",
    "    return np.array(x_train), y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56541c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for windowing test signal, predictions are recieved \n",
    "#from the model in batches to limit memory issues\n",
    "def windowtest(EMGtrain, spiketrain, window_size, model):\n",
    "    \n",
    "    EMGtrain = standardise(EMGtrain)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    predictions = []\n",
    "    count = 1\n",
    "    for i in range(30,EMGtrain.shape[0]-120):\n",
    "        x_train.append(EMGtrain[i-10:i+(window_size-10),:])\n",
    "        y_train.append(spiketrain[i, 0:5])\n",
    "        if count%8162 == 0:\n",
    "            predictions.append(model(np.array(x_train)))\n",
    "            x_train = []\n",
    "        count = count + 1\n",
    "            \n",
    "    y_train = np.array(y_train)\n",
    "    y_train2 = []\n",
    "    for i in range(5):\n",
    "        y_train2.append(y_train[:,i])\n",
    "    \n",
    "    return tf.concat(predictions, axis = 1), y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9222ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs a CNN model that recieves a HD-sEMG signal window as input and outputs\n",
    "#a 0 or 1 label based on wether the respective MU it has been trained to detect\n",
    "#is present in the signal. The number of these models in parallel can be given by MUs\n",
    "def convolutional_model(input_shape, filter_num, filter_size, dense_num, MUs):\n",
    "    input_signal = tf.keras.Input(shape = input_shape)\n",
    "    out = []\n",
    "    for i in range(1, MUs+1):\n",
    "        X = tfl.Conv1D(filter_num, filter_size, activation = 'relu')(input_signal)\n",
    "        X = tfl.Dropout(0.2)(X)\n",
    "        X = tfl.Flatten()(X)\n",
    "        X = tfl.Dense(dense_num, activation='relu')(X)\n",
    "        X = tfl.Dropout(0.5)(X)\n",
    "        output = tfl.Dense(1, activation = 'sigmoid', name='output_{}'.format(i))(X)\n",
    "        out.append(output)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input_signal, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0f73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds and compiles CNN model based on given parameters\n",
    "def build_model(window_size, filter_num, filter_size, dense_num, MUs):\n",
    "    model= convolutional_model((window_size, 192), filter_num, filter_size, dense_num, MUs)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  metrics = ['accuracy',RoA_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d035a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get stationary training set for training seperate models to be used in ensemble\n",
    "def getSmallTrainingSetExp2(training_noise, window_size, folder_name):  \n",
    "    training_folds = [1,2,3,4,5]\n",
    "    print(training_noise)\n",
    "    iter = False\n",
    "    for fold in training_folds:\n",
    "        EMGtrain = np.load('{}/{}_fold{}_x.npy'.format(folder_name, training_noise, fold))\n",
    "        spikes = np.load('{}/{}_fold{}_y.npy'.format(folder_name, training_noise, fold))\n",
    "        fold_windows , fold_spikes = windowtrain(EMGtrain, spikes, window_size)\n",
    "        if iter == False:\n",
    "            X = fold_windows\n",
    "            Y = np.array(fold_spikes)\n",
    "        else:\n",
    "            X = np.concatenate((X, fold_windows), axis = 0)\n",
    "            Y = np.concatenate((Y, np.array(fold_spikes)), axis = 1)\n",
    "        iter = True\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9f51a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models for the 5 different variations of training sets during\n",
    "#5-fold cross validation\n",
    "def trainModels(var, noises):\n",
    "    random.seed(60)\n",
    "    for training_noise in noises:\n",
    "        X, Y_raw = getSmallTrainingSetExp2(training_noise, 60, '{}_data'.format(var))\n",
    "        X, Y_shuffled = unison_shuffled_copies(X, np.array(Y_raw).T)\n",
    "        Y = []\n",
    "        for i in range(len(Y_raw)):\n",
    "            Y.append(Y_shuffled[:,i])\n",
    "        conv_model = build_model(60, 16, 4, 16, 5)\n",
    "        mc_vR= ModelCheckpoint('{}_models_exp2/bestvR_{}trained.h5'.format(var, training_noise), monitor='val_RoA_m', mode='max', verbose=0, save_best_only=True)\n",
    "        RoA_callback = AccuracyCallback('RoA_m')\n",
    "        history = conv_model.fit(X,\n",
    "                                 Y,\n",
    "                                 shuffle = True,\n",
    "                                 epochs = 100,\n",
    "                                 validation_split=0.2,\n",
    "                                 batch_size=256,\n",
    "                                 verbose = 0,\n",
    "                                 callbacks = [RoA_callback, mc_vR])\n",
    "        conv_model.save('{}_models_exp2/final_{}trained.h5'.format(var, training_noise))\n",
    "        print('Small model noise {} trained'.format(training_noise))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'noise'\n",
    "noises = ['20dB','15dB','10dB','5dB','0dB']\n",
    "trainModels(var,noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'MUs'\n",
    "noises = ['10MUs','20MUs','30MUs','40MUs','50MUs']\n",
    "trainModels(var,noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'lowpass'\n",
    "noises = ['500Hz', '300Hz', '200Hz', '150Hz', '125Hz']\n",
    "trainModels(var,noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'shift'\n",
    "noises = ['0mm','2mm','4mm','6mm','8mm']\n",
    "trainModels(var,noises)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
